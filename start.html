<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">

<title>Exam Title</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 16px;
      background: #f7f9fb;
      align-items: center;
      justify-content: center;
      height: 100vh;
      color:#111;
    }
    header { 
      display:flex;
      align-items:center;
      justify-content:space-between;
      position: relative;
      top: -30px;
    }
    #timer {
      white-space: nowrap; /* ensures the text stays in one line */
      width: auto;         /* automatically adjusts to content */
      font-size: 15px;
      color: #b22222;
      font-weight:700;
      /*margin-right: 35px;*/
    }
    #layout { 
      display:grid; 
      margin-top:100px; 
    }
    .panel { 
      background:white; 
      padding:12px; 
      border-radius:8px; 
      box-shadow:0 1px 6px rgba(0,0,0,0.08) 
    }
    video { 
      width: 100%; 
      border-radius:6px; 
      background: #000 
    }
    canvas.overlay{
      position:absolute;
      left:0;
      top:0;
      width:100%;
      height:100%;
      pointer-events:none;
    }

    #exam .question { 
      margin-bottom:12px; 
    }
    label { 
      cursor:pointer 
    }
    button { 
      padding:8px 12px; 
      border-radius:6px; 
      border:0; 
      background:#1e6fff; 
      color:white; 
      cursor:pointer 
    }
    button.secondary { 
      background:#444; 
      margin-left:8px 
    }
    #snapshots img { 
      max-width:100%; 
      display:block; 
      margin-bottom:8px; 
      border-radius:6px; 
    }
    small { 
      color:#666 
    }
	.correct { 
    color: green; 
    font-weight:bold 
  }
  .wrong { 
    color: red; 
    font-weight:bold 
  }
	#webcam {
	  position: fixed;
	  top: 40px;
	  right: 10px;
	  border: 2px solid #333;
	  width: 120px;
	  height: 100px;
	  overflow: hidden;
	}
	#camera {
	  width: 100%;
	  height: 100%;
	  object-fit: cover;
  }
	.question pre {
	  background: #f5f5f5;
	  border: 1px solid #ddd;
	  padding: 4px 8px;
	  margin: 2px 0;
	  border-radius: 4px;
	  display: inline-block;
	  white-space: pre-wrap; /* keep line breaks and wrap long lines */
	  font-family: monospace;
	  font-size: 14px;
	}
  .button-row {
    display: none;
    justify-content: space-between; /* pushes buttons to opposite sides */
    width: 100%;
    margin-top: 12px;
  }
  #prevBtn, #nextBtn {
    padding: 10px 20px;
  }
  #prevBtn:hover {
    opacity: 0.7;
  }
  #nextBtn:hover {
    opacity: 0.7;
  }
  .button-group {
    display: none; /* required for margin:auto centering */
    margin: 40px auto 0;
    background: linear-gradient(90deg, #6aa3ff, #1ea3ff, #0fa0ff);
    border-radius: 12px;
    padding: 10px 40px;
    color: white;
    font-weight: bold;
    text-align: center;
    cursor: pointer;
    transition: opacity 0.3s ease;
    font-size: 16px;
  }
  .button-group:hover {
    opacity: 0.6;
  }
  #homeBtn {
    display: none; /* required for margin:auto centering */
    margin: 20px auto 0;
    background: linear-gradient(90deg, #90e9bb, #5ac055, #17650c);
    border-radius: 12px;
    padding: 10px 40px;
    color: white;
    font-weight: bold;
    text-align: center;
    cursor: pointer;
    transition: opacity 0.3s ease;
    font-size: 16px;
  }
  #homeBtn:hover {
    opacity: 0.6;
  }

  #toggleOneAtTime {
    font-weight: bold;
    background: #8791a1;
    color: white;
    border: none;
    position: absolute;
    top: 160px;  /* moves it near top of layout */
    width: 30px;
    height: 30px;
    border-radius: 6px;
    cursor: pointer;
    align-items: center;
    justify-content: center;
    font-size: 8px;
    transition: opacity 0.3s ease;
  }
  #toggleOneAtTime:hover {
    opacity: 0.8;
  }
  #toggleOneAtTime i {
    margin-right: 6px;
  }
  </style>
</head>
<body>
  <!-- Eye-Tracking -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>

  <header>
    <h1 id="examTitle">Proctored Exam</h1>
  </header>

  <div style="margin-top:8px">
    <button id="toggleOneAtTime" style="display:none">
      <i class="fa-solid fa-chevron-down"></i>
    </button>
  </div>

  <!-- Webcam -->
  <div id="webcam">
    <div id="timer">Time Left: --:--</div>
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay" class="overlay"></canvas> <!-- face detection -->
  </div>
  
  <div id="layout">
    <div id="content" class="panel" class="center-box">
      <div id="exam"></div>

      <div class="button-row">
        <button id="prevBtn" class="secondary">Previous</button>
        <button id="nextBtn" class="secondary">Next</button>
      </div>

      <button id="submitBtn" class="button-group">Submit</button>
      <button id="homeBtn" onclick="window.location.href='index.html'"><i class="fa fa-house"></i></button>

      <div id="result" style="margin-top:12px"></div>
    </div>
  </div>

<script>
/* -------------------------
   Exam parsing & rendering
   ------------------------- */
let answers = [];        // expected answers, in order
let timeLeft = 60 * 60;   // default: 15 minutes, change before start
let timerInterval = null;
let recordingActive = false;
let oneAtTime = true;
let currentIndex = 0;

document.getElementById('toggleOneAtTime').addEventListener('click', toggleOneAtTime);
document.getElementById('prevBtn').addEventListener('click', () => showQuestion(currentIndex-1));
document.getElementById('nextBtn').addEventListener('click', () => showQuestion(currentIndex+1));
document.getElementById('submitBtn').addEventListener('click', submitExam);

//window.onload = function() {
window.onload = async function() {

  try {
    // ask for webcam
    await startCamera();

    // start Microphone
     try {
      await startMicrophone();
    } catch (micErr) {
      console.warn("Microphone error:", micErr);
      alert("‚ö† Microphone access denied. Noise monitoring disabled.");
    }

    // Load questions
    const savedTitle = localStorage.getItem("saveTitle");
    const savedContent = localStorage.getItem("saveContent");

    if (savedTitle) {
      document.getElementById("examTitle").textContent = savedTitle;
    }
  
    if (savedContent) {
      parseQuestions(savedContent);
    }
    
    // show layout after content is ready
    document.getElementById("layout").style.display = "grid";

    // show navigation buttons after questions are loaded
    document.getElementById("toggleOneAtTime").style.display = "inline-block";
    document.querySelector('.button-row').style.display = 'flex'; // show
    document.getElementById('submitBtn').style.display = 'block'; // show
    document.getElementById('homeBtn').style.display = 'block'; // show

    startTimer();
  } catch(err) {
	  alert('‚ùå Camera error or permission denied: ' + err.message);
  };
};

/* -------------------------
   Microphone
   ------------------------- */
// Config
const NOISE_THRESHOLD = 0.14;   // When ‚Äútoo loud‚Äù
const SPEAK_THRESHOLD = 0.18;   // When voice detected
const MAX_NOISE_TIME = 5;       // Seconds before auto-fail

let noiseSeconds = 0;
let lastNoiseTime = 0;
let failed = false;

async function startMicrophone() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;

        const freqAnalyser = audioCtx.createAnalyser();
        freqAnalyser.fftSize = 512;

        const mic = audioCtx.createMediaStreamSource(stream);
        mic.connect(analyser);
        mic.connect(freqAnalyser);

        const timeData = new Uint8Array(analyser.fftSize);
        const freqData = new Uint8Array(freqAnalyser.frequencyBinCount);

        function update() {
            analyser.getByteTimeDomainData(timeData);
            freqAnalyser.getByteFrequencyData(freqData);

            // Calculate volume (RMS)
            let sum = 0;
            for (let i = 0; i < timeData.length; i++) {
                const v = (timeData[i] - 128) / 128;
                sum += (v * v);
            }
            const volume = Math.sqrt(sum / timeData.length);

            //console.log('volume = ', volume);

            // Check for noise / speaking
            if (volume > SPEAK_THRESHOLD) {
                console.log('üé§ Someone is speaking!');
                alert('üé§ Someone is speaking!');
                lastNoiseTime = Date.now();
            } else if (volume > NOISE_THRESHOLD) {
                console.log('‚ö† Too loud!');
                alert('‚ö† Too loud!');
                lastNoiseTime = Date.now();
            } else {
                //alertBox.textContent = "";
            }

            // Count continuous noise time
            if (Date.now() - lastNoiseTime < 1000)
              noiseSeconds++;
            else
              noiseSeconds = 0;

            //console.log('noiseSeconds = ', noiseSeconds);

            // Auto-fail
            if (!failed && noiseSeconds >= MAX_NOISE_TIME) {
                failed = true;
                alert("‚ùå Exam failed: too much noise.");
            }

            requestAnimationFrame(update);
        }

        update();

    } catch (e) {
        alert("Microphone error: " + e.message);
    }
}

function parseQuestions(text){
  // split by blocks that start with '*' (like your sample)  
  const blocks = text
  .split(/\n\s*\*/g)  // split only when * starts a new block
  .map(b => b.replace(/^\s*\*/, "").trim())  // remove leading *
  .filter(Boolean);
  
  answers = [];
  const examDiv = document.getElementById('exam');
  examDiv.innerHTML = '';
  blocks.forEach((block, idx) => {
    // split off "answer =" if present
    const parts = block.split(/answer\s*=\s*/i);
    const qPart = parts[0].trim();
	const ans = parts[1]
      ? parts[1].trim().split(",").map(a => a.trim().toLowerCase())
      : [];
    answers.push(ans);

    const container = document.createElement('div');
    container.className = 'question';
    container.id = 'q' + idx;

    // first non-empty line is question title
    const lines = qPart.split(/\r?\n/).map(l=>l.trim()).filter(Boolean);
    const title = lines.shift() || `Question ${idx+1}`;
    const h = document.createElement('h3');
    h.textContent = `${idx+1}: ${title}`;
    container.appendChild(h);

	const correctAns = answers[idx];  // array of correct answers
	const inputType = correctAns.length > 1 ? "checkbox" : "radio";

	lines.forEach((line, i) => {
      // options usually like "a. text"
      const optMatch = line.match(/^([a-z])\.\s*(.*)$/);
      if(optMatch){
        const opt = optMatch[1].toLowerCase();
		
		// collect multi-line continuation
		let optText = optMatch[2];
		let j = i + 1;
		while (j < lines.length && /^\s/.test(lines[j])) {
		  optText += "\n" + lines[j];
		  j++;
		}
		i = j - 1; // skip collected lines
	
		// escape before inserting
		const safeText = escapeHtml(optText);
  
        const label = document.createElement('label');
        label.innerHTML = `<input type="${inputType}" name="q${idx}" value="${opt}"> ${optMatch[1]}. ${safeText}`;
		container.appendChild(label);
        container.appendChild(document.createElement('br'));
      } else {
        // non-option lines (extra) - show as text
        const p = document.createElement('p');
        p.textContent = line;
        container.appendChild(p);
      }
    });

    examDiv.appendChild(container);
  });

  // if oneAtTime default off, show all; otherwise show only first
  if(oneAtTime) showQuestion(0);
}

document.querySelectorAll('#exam input').forEach(inp => {
	  inp.disabled = false;   // make sure it‚Äôs enabled
	  inp.checked = false;    // uncheck it
	});

function handleFile(ev){
  const f = ev.target.files[0];
  if(!f) return;
  const r = new FileReader();
  r.onload = e => {
    parseQuestions(e.target.result);
  }
  r.readAsText(f);
}

function escapeHtml(str) {
  return str
    .replace(/&/g, "&amp;")
    .replace(/</g, "&lt;")
    .replace(/>/g, "&gt;")
    .replace(/"/g, "&quot;")
    .replace(/'/g, "&#039;");
}

function startTimer(){
  // you can set timeLeft before startingExam if desired
  updateTimerDisplay();
  timerInterval = setInterval(() => {
    timeLeft--;
    updateTimerDisplay();
    if(timeLeft <= 0){
      clearInterval(timerInterval);
      submitExam();
    }
  }, 1000);
}

function updateTimerDisplay(){
  const minutes = Math.max(0, Math.floor(timeLeft / 60));
  const seconds = Math.max(0, timeLeft % 60);
  document.getElementById('timer').textContent = `Time Left: ${minutes}:${seconds < 10 ? '0' : ''}${seconds}`;
}

/* -------------------------
   Grading / Submit
   ------------------------- */
function submitExam(){
  // stop timer
  if(timerInterval) { clearInterval(timerInterval); timerInterval = null; }
  
  // stop recording
  if(recordingActive) toggleRecording(); // stops recorder and creates file
  
  // grade
  let score = 0, answered = 0;
  let reportScore = '<hr class="results-separator"><h2>Exam Results:</h2>';
  let reportHtml = "";


  answers.forEach((ans, i) => { 
	const selected = Array.from(document.querySelectorAll(`input[name="q${i}"]:checked`))
						  .map(x => x.value);
	
	if (selected.length > 0) {
	  answered++;

	  // sort both for easy comparison
	  const correct = [...answers[i]].sort().join(",");
	  const chosen = [...selected].sort().join(",");

	  if (correct === chosen) {
		score++;
		reportHtml += `<p>${i+1}: <span class="correct">Correct</span></p>`;
	  } else {
		reportHtml += `<p>${i+1}: <span class="wrong">Wrong</span> ‚Äî Your answers: ${selected.join(",")} , Correct: ${answers[i].join(",")}</p>`;
	  }
	} else {
	  reportHtml += `<p>${i+1}: <span class="wrong">Not Answered</span> ‚Äî Correct: ${answers[i].join(",")}</p>`;
	}
  });
  
  const percent = ((score / answers.length) * 100).toFixed(1);
  const status = percent >= 70 ? "‚úÖ PASSED" : "‚ùå NOT PASSED";
  reportScore += `<p><strong>Score: ${score}/${answers.length} (${percent}%) ‚Üí <b>${status}</b></strong></p>`;
  
  document.getElementById("result").innerHTML = reportScore + reportHtml;
  // disable inputs
  document.querySelectorAll('#exam input').forEach(inp => inp.disabled = true);
  document.getElementById('submitBtn').disabled = true;
  // keep video running (video saved) or stop stream if you prefer
}

/* -------------------------
   One question at a time
   ------------------------- */
function toggleOneAtTime(){
  oneAtTime = !oneAtTime;
  const btn = document.getElementById('toggleOneAtTime');
  const icon = btn.querySelector('i');

  if(oneAtTime) {
    btn.innerHTML = '<i class="fa-solid fa-chevron-down"></i>';
    showQuestion(0);
  }
  else {
    // reveal all
    btn.innerHTML = '<i class="fa-solid fa-chevron-up"></i>';
    document.querySelectorAll('#exam .question').forEach(q=> q.style.display = '');
  }
}

function showQuestion(index){
  const qs = document.querySelectorAll('#exam .question');
  if(index < 0) index = 0;
  if(index >= qs.length) index = qs.length - 1;
  currentIndex = index;
  qs.forEach((q,i) => q.style.display = (i===index ? '' : 'none'));
}

/* -------------------------
   Camera
   ------------------------- */
let stream = null;
let mediaRecorder = null;
let recordedChunks = [];
let snapshotTimer = null;
let isCameraStarted = false;

const video = document.getElementById('video');
const toggleRecordingBtn = document.getElementById('toggleRecording');
const downloadRecordingBtn = document.getElementById('downloadRecording');

async function startCamera(){
  if(stream) return; // already started

  try {
    // Eye-Tracking
    const faceMesh = new window.FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true, // IMPORTANT ‚Üí gives iris landmarks (468-478)
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    faceMesh.onResults(onResults);

    // Start camera
    const cam = new window.Camera(video, {
      onFrame: async () => {
        await faceMesh.send({ image: video });
      },
      width: 480,
      height: 360,
    });
    cam.start();

    /*****/
/*
    // Old
    // get camera (and optionally audio)
    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
    video.srcObject = stream;

    await video.play();
*/

    // set canvas size to video display size
    document.getElementById("overlay").style.display = "none"; // hide detection rectangle, hide = "none", show = "block"

    overlay.width = video.videoWidth || video.clientWidth;
    overlay.height = video.videoHeight || video.clientHeight;

    console.log('Camera started');

    //-------------------------------------//
    
    // Face detection
    // lazy-load TF and model after camera starts
    await loadModelIfNeeded();
    startDetectLoop();

    isCameraStarted = true;

  } catch(e) {
    console.log('Camera error', e);
    alert('Camera error', e);
  }

  function stopCamera(){
    if (stream){
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }
    video.pause();
    video.srcObject = null;
    stopDetectLoop();
    console.log('Camera stopped');
    ctx && ctx.clearRect(0,0,overlay.width, overlay.height);
}

  /*
  // prepare MediaRecorder but don't start until toggleRecording
  const options = { mimeType: 'video/webm;codecs=vp8,opus' };

  try {
    mediaRecorder = new MediaRecorder(mediaStream, options);
  } catch(e) {
    mediaRecorder = new MediaRecorder(mediaStream); // fallback
  }
  mediaRecorder.ondataavailable = e => {
    if(e.data && e.data.size > 0) recordedChunks.push(e.data);
  };

  mediaRecorder.onstop = () => {
    createRecordingBlob();
  };
  */
}

/* -------------------------
   FACE DETECTION
   ------------------------- */
let model = null;
let detectLoopId = null;
let overlay = document.getElementById('overlay');
let ctx = overlay.getContext('2d');
let lastFaceState = 'unknown'; // 'no_face'|'one_face'|'multi'

// Detection loop
let lastDetectTime = 0;
async function detectOnce(){
  if (!model || !video || video.readyState < 2) return;

  const now = performance.now();

  // throttle to ~700ms
  if (now - lastDetectTime < 600) return;
  lastDetectTime = now;
  const returnTensors = false;
  const predictions = await model.estimateFaces(video, returnTensors);

  // predictions is array of face objects with topLeft, bottomRight, probability
  ctx.clearRect(0,0,overlay.width, overlay.height);
  let state = 'no_face';

  //console.log('predictions.length = ', predictions.length);
  
  if (!predictions || predictions.length === 0) {
    state = 'no_face';
  } else if (predictions.length === 1) {
    state = 'one_face';

    // draw box
    const p = predictions[0];
    const [x1,y1] = p.topLeft;
    const [x2,y2] = p.bottomRight;
    const w = x2-x1, h = y2-y1;
    ctx.strokeStyle = 'rgba(6,182,212,0.9)';
    ctx.lineWidth = 3;
    ctx.strokeRect(x1, y1, w, h);
    // label
    ctx.fillStyle = 'rgba(6,182,212,0.1)';
    ctx.fillRect(x1, y1-24, 120, 20);
    ctx.fillStyle = '#042028';
    ctx.font = '14px sans-serif';
    ctx.fillText('face detected', x1+6, y1-9);
  } else {
    state = 'multi';
    // draw multi boxes
    predictions.forEach(p => {
      const [x1,y1] = p.topLeft;
      const [x2,y2] = p.bottomRight;
      const w = x2-x1, h = y2-y1;
      ctx.strokeStyle = 'rgba(255,110,96,0.95)';
      ctx.lineWidth = 3;
      ctx.strokeRect(x1, y1, w, h);
    });
    ctx.fillStyle = 'rgba(255,110,96,0.12)';
    ctx.fillRect(8, 8, 220, 26);
    ctx.fillStyle = '#3a0f07';
    ctx.font = '14px sans-serif';
    ctx.fillText('Multiple faces detected ‚Äî please have only one person', 14, 25);
  }

  // state transitions
  if (state !== lastFaceState) {
    // log event
    if (state === 'no_face') {
      alert('No face detected. Please stay in view of the camera.');
      console.log('No face detected. Please stay in view of the camera.');
    } else if (state === 'multi') {
      alert('Multiple faces detected. Only one person should take the exam.');
      console.log('Multiple faces detected. Only one person should take the exam.');
    } else if (state === 'one_face') {
      //alert('Single face detected');
      console.log('Single face detected');
    }
    lastFaceState = state;
  }
}

function startDetectLoop(){
  if (detectLoopId) return;
  detectLoopId = setInterval(() => {
    detectOnce().catch(e => console.error('detect error', e));
  }, 700);
  console.log('Detection started');
}

function stopDetectLoop(){
  if (detectLoopId) {
    clearInterval(detectLoopId);
    detectLoopId = null;
  }
  console.log('Detection stopped');
}

function loadScript(src){
  return new Promise((resolve, reject) => {
    const s = document.createElement('script');
    s.src = src;
    s.onload = () => resolve();
    s.onerror = e => reject(e);
    document.head.appendChild(s);
  });
}

// Load TF.js and BlazeFace if needed
async function loadModelIfNeeded(){
  if (model) return;

  console.log('Loading model (may take a few seconds)...');

  // load TF.js
  if (!window.tf) {
    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js');
  }
  if (!window.blazeface) {
    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js');
  }
  // load model
  model = await blazeface.load();
  console.log('Model loaded');
}

/* -------------------------
   Eye-Tracking
   ------------------------- */
const canvas = document.getElementById("overlay");

let lastBlinkTime = 0;
let blinkCount = 0;

function distance(a, b) {
  return Math.hypot(a.x - b.x, a.y - b.y);
}

function getEyeOpenness(landmarks, top, bottom) {
  return distance(landmarks[top], landmarks[bottom]);
}

function analyzeEyes(landmarks) {
  // MediaPipe eye landmark indices
  const LEFT_TOP = 159;
  const LEFT_BOTTOM = 145;
  const RIGHT_TOP = 386;
  const RIGHT_BOTTOM = 374;

  const leftOpenness = getEyeOpenness(landmarks, LEFT_TOP, LEFT_BOTTOM);
  const rightOpenness = getEyeOpenness(landmarks, RIGHT_TOP, RIGHT_BOTTOM);

  const avgOpenness = (leftOpenness + rightOpenness) / 2;

  if (avgOpenness < 0.01) {
    const now = Date.now();
    if (now - lastBlinkTime > 300) {
      blinkCount++;
      lastBlinkTime = now;
    }

    //alert('NO BLINK');
    return "BLINK";
  }

  return "OPEN";
}

function getGazeDirection(landmarks) {
  // Eye corner indices
  const leftEyeLeft = landmarks[33];
  const leftEyeRight = landmarks[133];
  const leftPupil = landmarks[468]; // iris center

  const eyeWidth = distance(leftEyeLeft, leftEyeRight);
  const pupilOffset = (leftPupil.x - leftEyeLeft.x) / eyeWidth;

  if (pupilOffset < 0.32) {
    alert('NO LOOK TO THE RIGHT');
    return "LOOKING RIGHT";
  }

  if (pupilOffset > 0.68) {
    alert('NO LOOK TO THE LEFT');
    return "LOOKING LEFT";
  }

  return "CENTER";
}

function onResults(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

  if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
    ctx.fillStyle = "red";
    ctx.fillText("FACE NOT DETECTED", 10, 20);
    return;
  }

  const landmarks = results.multiFaceLandmarks[0];

  // Draw mesh
  window.drawConnectors(ctx, landmarks, window.FACEMESH_TESSELATION, { color: "#0f0" });

  // Eye state
  const eyeState = analyzeEyes(landmarks);
  const gaze = getGazeDirection(landmarks);

  ctx.fillStyle = "yellow";
  /*
  ctx.fillText(`Eyes: ${eyeState}`, 10, 20);
  ctx.fillText(`Gaze: ${gaze}`, 10, 40);
  ctx.fillText(`Blink Count: ${blinkCount}`, 10, 60);
  */
  console.log('Eyes: ', eyeState);
  console.log('Gaze: ', gaze);
  console.log('Blink Count: ', blinkCount);
}

/* -------------------------
   Screen-switch-detection
   ------------------------- */
let violations = 0;
const MAX_VIOLATIONS = 10;

function log(msg) {
    const t = new Date().toLocaleTimeString();
    logBox.textContent += `[${t}] ${msg}\n`;
}

function addViolation(reason) {
    violations++;
    alert(`‚ùå Violation #${violations}: ${reason}`);
    //log(`‚ùå Violation #${violations}: ${reason}`);

    if (violations >= MAX_VIOLATIONS) {
        alert("‚ùå Exam failed. Too many violations.");
        // End exam
    }
}

// Block Keyboard Shortcuts (as many as possible)
document.addEventListener("keydown", (e) => {
    const blockedCombos = [
        e.ctrlKey && e.key === "t",
        e.ctrlKey && e.key === "w",
        e.ctrlKey && e.key === "n",
        e.ctrlKey && e.key === "r",
        e.key === "F11",
        e.key === "F5",
        e.key === "Escape",
        //e.key === "F12", // Devtools
    ];

    if (blockedCombos.some(Boolean)) {
        e.preventDefault();
        addViolation(`Blocked shortcut: ${e.key}`);
    }
});

/******/

// Detect DevTools Opening (3 methods combined)
// Method A ‚Äî Size check
/*
setInterval(() => {
  if(isCameraStarted) {
    const threshold = 160;
    if (window.outerWidth - window.innerWidth > threshold ||
        window.outerHeight - window.innerHeight > threshold) {
        addViolation("DevTools detected (resize)");
    }
  }
}, 1000);
*/
// Method B ‚Äî Debugger trap
let check = false;
setInterval(() => {
  if(isCameraStarted) {
    const start = Date.now();
    if (Date.now() - start > 10) {
        addViolation("DevTools detected (debugger slowdown)");
    }
  }
}, 2000);

// Method C ‚Äî Console open check
console.log("%cSTOP", "font-size: 100px; color: red;");

/******/

// Screen-switch detection (tab change + blur/focus)
document.addEventListener("visibilitychange", () => {
    if (document.hidden) addViolation("Tab switch or minimize");
});
/*
window.addEventListener("blur", () => {
    addViolation("Window lost focus (possible Alt+Tab)");
});
*/
/******/

// Detect leaving fullscreen
document.addEventListener("fullscreenchange", () => {
    if (!document.fullscreenElement) addViolation("Exited fullscreen");
});

/******/

// Fake ‚ÄúSecond Monitor Detection‚Äù (best possible)
let originalWidth = window.screen.width;

setInterval(() => {
  if(isCameraStarted) {
    if (window.screen.width !== originalWidth) {
        addViolation("Possible second monitor usage");
    }
  }
}, 3000);

/******/


// Virtual Desktop Detection (limited)
/*
let last = Date.now();
setInterval(() => {
  if(isCameraStarted) {
    let now = Date.now();
    if (now - last > 3000) {
        addViolation("Virtual desktop or system switch detected");
    }
    last = now;
  }
}, 1000);
*/

/******/

/*
function createRecordingBlob(){
  const blob = new Blob(recordedChunks, { type: 'video/webm' });
  const url = URL.createObjectURL(blob);
  // enable download button and set href via link
  downloadRecordingBtn.disabled = false;
  downloadRecordingBtn.onclick = () => {
    const a = document.createElement('a');
    a.href = url;
    a.download = `exam_recording_${new Date().toISOString().replace(/[:.]/g,'-')}.webm`;
    document.body.appendChild(a);
    a.click();
    a.remove();
  };
  // optionally show link in page:
  const d = document.createElement('div');
  d.innerHTML = `<p><small>Recording finished. <button id="dl2">Download</button></small></p>`;
  document.getElementById('content').appendChild(d);
  document.getElementById('dl2').onclick = downloadRecordingBtn.onclick;
}
*/
/* -------------------------
   Snapshot function
   ------------------------- */
/*
function takeSnapshot(){
  if(!mediaStream) return;
  const videoTrack = mediaStream.getVideoTracks()[0];
  if(!videoTrack) return;
  const canvas = document.createElement('canvas');
  const v = preview;
  canvas.width = v.videoWidth || 320;
  canvas.height = v.videoHeight || 240;
  const ctx = canvas.getContext('2d');
  try {
    ctx.drawImage(v, 0, 0, canvas.width, canvas.height);
    const img = new Image();
    img.src = canvas.toDataURL('image/jpeg', 0.8);
    img.title = new Date().toLocaleTimeString();
    const wrapper = document.createElement('div');
    wrapper.appendChild(img);
    wrapper.appendChild(document.createElement('br'));
    document.getElementById('snapshots').prepend(wrapper);
    // optionally store snapshot data to upload to server
  } catch(e) {
    console.warn('Snapshot failed', e);
  }
}
*/

/* -------------------------
   Download recording helper
   ------------------------- */
function downloadRecording(){
  // implemented by createRecordingBlob -> sets downloadRecordingBtn.onclick
  // here we just call the click handler if ready
  if(downloadRecordingBtn.onclick) downloadRecordingBtn.onclick();
}

/* -------------------------
   initialize small defaults
   ------------------------- */
//document.getElementById('startExamBtn').disabled = true;
//document.getElementById('submitBtn').disabled = false;

</script>
</body>
</html>